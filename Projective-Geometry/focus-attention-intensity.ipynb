{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-19T13:49:45.224907Z",
     "iopub.status.busy": "2025-04-19T13:49:45.224641Z",
     "iopub.status.idle": "2025-04-19T13:49:45.229610Z",
     "shell.execute_reply": "2025-04-19T13:49:45.228780Z",
     "shell.execute_reply.started": "2025-04-19T13:49:45.224885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You may also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:50:53.165817Z",
     "iopub.status.busy": "2025-04-19T13:50:53.165262Z",
     "iopub.status.idle": "2025-04-19T13:57:09.530644Z",
     "shell.execute_reply": "2025-04-19T13:57:09.529897Z",
     "shell.execute_reply.started": "2025-04-19T13:50:53.165791Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 172MB/s]\n",
      "  0%|          | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [05:56<00:00,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ðŸ“Š Real Images (Average) ===\n",
      "Focus Score     : 0.4390\n",
      "Attention Spread: 0.4117\n",
      "Intensity       : 0.4390\n",
      "\n",
      "=== ðŸ§ª Fake Images (Average) ===\n",
      "Focus Score     : 0.4361\n",
      "Attention Spread: 0.4068\n",
      "Intensity       : 0.4361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model.to(device)\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.gradients = grad_out[0].detach()\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def generate(self, image_tensor, class_idx=None):\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        self.model.eval()\n",
    "        output = self.model(image_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1).item()\n",
    "        self.model.zero_grad()\n",
    "        output[0, class_idx].backward()\n",
    "        weights = self.gradients.mean(dim=[2, 3], keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = F.relu(cam)\n",
    "        cam = F.interpolate(cam, size=image_tensor.shape[2:], mode='bilinear', align_corners=False)\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        return cam\n",
    "\n",
    "def apply_heatmap(image_tensor, cam):\n",
    "    image_np = image_tensor.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    overlay = (0.4 * heatmap / 255.0 + 0.6 * image_np)\n",
    "    return np.clip(overlay, 0, 1)\n",
    "\n",
    "def focus_score(cam):\n",
    "    return np.sum(cam) / cam.size\n",
    "\n",
    "def attention_coverage(cam, threshold=0.5):\n",
    "    return np.sum(cam > threshold) / cam.size\n",
    "\n",
    "def intensity(cam):\n",
    "    return np.mean(cam)\n",
    "\n",
    "def calculate_independent_metrics(cam):\n",
    "    return focus_score(cam), attention_coverage(cam), intensity(cam)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "real_paths = sorted(glob.glob('/kaggle/input/flowers-real/**/*.jpg', recursive=True))[:3000]\n",
    "fake_paths = sorted(glob.glob('/kaggle/input/flower-102-real/**/*.jpg', recursive=True))[:3000]\n",
    "assert len(real_paths) == len(fake_paths), \"Mismatch in dataset length!\"\n",
    "\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "grad_cam = GradCAM(model, model.layer4[1].conv2)\n",
    "\n",
    "real_metrics = []\n",
    "fake_metrics = []\n",
    "\n",
    "for idx, (real_img_path, fake_img_path) in enumerate(tqdm(zip(real_paths, fake_paths), total=len(real_paths))):\n",
    "    try:\n",
    "        real_img = Image.open(real_img_path).convert('RGB')\n",
    "        fake_img = Image.open(fake_img_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading images at index {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "    real_tensor = transform(real_img).unsqueeze(0).to(device)\n",
    "    fake_tensor = transform(fake_img).unsqueeze(0).to(device)\n",
    "\n",
    "    real_cam = grad_cam.generate(real_tensor)\n",
    "    fake_cam = grad_cam.generate(fake_tensor)\n",
    "\n",
    "    real_metrics.append(calculate_independent_metrics(real_cam))\n",
    "    fake_metrics.append(calculate_independent_metrics(fake_cam))\n",
    "\n",
    "    real_overlay = apply_heatmap(real_tensor, real_cam)\n",
    "    fake_overlay = apply_heatmap(fake_tensor, fake_cam)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(real_overlay)\n",
    "    axs[0].set_title(\"Real\")\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(fake_overlay)\n",
    "    axs[1].set_title(\"Fake\")\n",
    "    axs[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "\n",
    "real_metrics = np.array(real_metrics)\n",
    "fake_metrics = np.array(fake_metrics)\n",
    "\n",
    "print(\"\\n=== ðŸ“Š Real Images (Average) ===\")\n",
    "print(f\"Focus Score     : {real_metrics[:,0].mean():.4f}\")\n",
    "print(f\"Attention Spread: {real_metrics[:,1].mean():.4f}\")\n",
    "print(f\"Intensity       : {real_metrics[:,2].mean():.4f}\")\n",
    "\n",
    "print(\"\\n=== ðŸ§ª Fake Images (Average) ===\")\n",
    "print(f\"Focus Score     : {fake_metrics[:,0].mean():.4f}\")\n",
    "print(f\"Attention Spread: {fake_metrics[:,1].mean():.4f}\")\n",
    "print(f\"Intensity       : {fake_metrics[:,2].mean():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7188858,
     "sourceId": 11471166,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7189953,
     "sourceId": 11472642,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
